{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "future2stock = {'JBF': 3443, 'QWF': 2388, 'HCF': 2498, 'DBF': 2610, 'EHF': 1319, 'IPF': 3035, 'IIF': 3006, 'QXF': 2615, 'PEF': 5425, 'NAF': 3105}\n",
    "future_path = r'processedData_2023\\\\futures'\n",
    "stock_path = r'processedData_2023\\\\stocks'\n",
    "future_files = os.listdir(future_path)\n",
    "stock_files = os.listdir(stock_path)\n",
    "# only keep end with _202306.csv.gz\n",
    "future_files = [file for file in future_files if file.endswith('_202306.csv.gz')]\n",
    "stock_files = [file for file in stock_files if file.endswith('_202306.csv.gz')]\n",
    "# Get all the future tickers\n",
    "future_data = {}\n",
    "stock_data = {}\n",
    "for future_ticker, stock_ticker in future2stock.items():\n",
    "    future_data[future_ticker] = pd.DataFrame()\n",
    "    stock_data[stock_ticker] = pd.DataFrame()\n",
    "    for file in future_files:\n",
    "        if file.startswith(future_ticker):\n",
    "            tmp = pd.read_csv(os.path.join(future_path, file), compression='gzip')    \n",
    "            tmp = tmp[tmp['askPrice1'] > 0]\n",
    "            tmp = tmp[tmp['bidPrice1'] > 0]\n",
    "            tmp = tmp[tmp['askPrice1'] > tmp['bidPrice1']]\n",
    "            future_data[future_ticker] = pd.concat([future_data[future_ticker], tmp])\n",
    "            \n",
    "    for file in stock_files:\n",
    "        if file.startswith(str(stock_ticker)):\n",
    "            tmp = pd.read_csv(os.path.join(stock_path, file), compression='gzip')\n",
    "            tmp = tmp[tmp['SP1'] > 0]\n",
    "            tmp = tmp[tmp['BP1'] > 0]\n",
    "            tmp = tmp[tmp['SP1'] > tmp['BP1']]\n",
    "            stock_data[stock_ticker] = pd.concat([stock_data[stock_ticker], tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select common dates and indexing\n",
    "for future_ticker, futureData in future_data.items():\n",
    "    stockData = stock_data[future2stock[future_ticker]]\n",
    "    stockData_dates = np.unique(stockData.date)\n",
    "    stoD=pd.to_datetime(stockData_dates, format=\"%Y-%m-%d\")\n",
    "    qqqq=stoD.year*10000+stoD.month*100+stoD.day\n",
    "    \n",
    "    indexData_dates = np.unique(futureData.date)\n",
    "    indD=pd.to_datetime(indexData_dates, format=\"%Y-%m-%d\")\n",
    "    pppp=indD.year*10000+indD.month*100+indD.day\n",
    "    \n",
    "    commonDays=pd.to_datetime(pppp.intersection(qqqq),format=\"%Y%m%d\")\n",
    "    \n",
    "    d_futures=pd.to_datetime(futureData.date,format=\"%Y-%m-%d\")\n",
    "    futureData.date=d_futures\n",
    "    futureData=futureData[futureData.date.isin(commonDays)]\n",
    "\n",
    "    d_stock=pd.to_datetime(stockData.date,format=\"%Y-%m-%d\")\n",
    "    stockData.date=d_stock\n",
    "    stockData=stockData[stockData.date.isin(commonDays)]\n",
    "\n",
    "    stockData_DateTime = pd.to_datetime(stockData.date.astype(str) + ' ' + stockData.time.astype(str), format=\"%Y-%m-%d %H%M%S%f\")\n",
    "    futuresData_DateTime = pd.to_datetime(futureData.date.astype(str) + ' ' + futureData.time.astype(str), format=\"%Y-%m-%d %H%M%S%f\")\n",
    "\n",
    "    stockData.index = stockData_DateTime\n",
    "    stockData = stockData[~stockData.index.duplicated(keep='last')]\n",
    "\n",
    "    futureData.index = futuresData_DateTime\n",
    "    futureData = futureData[~futureData.index.duplicated(keep='last')]\n",
    "    \n",
    "    stockData = stockData.sort_index()\n",
    "    futureData = futureData.sort_index()\n",
    "    \n",
    "    stock_data[future2stock[future_ticker]] = stockData\n",
    "    future_data[future_ticker] = futureData\n",
    "    \n",
    "# Downsampling\n",
    "freq = '10s'\n",
    "for future_ticker, futureData in future_data.items():\n",
    "    stockData = stock_data[future2stock[future_ticker]]\n",
    "    stockData = stockData.groupby(stockData.index.date).apply(lambda x: x.resample(freq, closed='left', label='right').last()).reset_index(level=0, drop=True)\n",
    "    futureData = futureData.groupby(futureData.index.date).apply(lambda x: x.resample(freq, closed='left', label='right').last()).reset_index(level=0, drop=True)\n",
    "    stockData.fillna(method='ffill', inplace=True)\n",
    "    futureData.fillna(method='ffill', inplace=True)\n",
    "    # get the common index\n",
    "    comon_index = stockData.index.intersection(futureData.index)\n",
    "    stock_data[future2stock[future_ticker]] = stockData.loc[comon_index]\n",
    "    future_data[future_ticker] = futureData.loc[comon_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order Slope\n",
    "def cal_slope(df):\n",
    "    # Consider future and stock difference\n",
    "    if 'bidSize1' in df.columns:\n",
    "        bidSizes = [f'bidSize{i}' for i in range(1, 6)]\n",
    "        bidPrices = [f'bidPrice{i}' for i in range(1, 6)]\n",
    "        askSizes = [f'askSize{i}' for i in range(1, 6)]\n",
    "        askPrices = [f'askPrice{i}' for i in range(1, 6)]\n",
    "    else:\n",
    "        bidSizes = [f'BV{i}' for i in range(1, 6)]\n",
    "        bidPrices = [f'BP{i}' for i in range(1, 6)]\n",
    "        askSizes = [f'SV{i}' for i in range(1, 6)]\n",
    "        askPrices = [f'SP{i}' for i in range(1, 6)]\n",
    "\n",
    "    df_bid = df[bidSizes + bidPrices].copy()\n",
    "    df_ask = df[askSizes + askPrices].copy()\n",
    "    df_bid.loc[:, bidPrices] = df_bid[bidPrices] / df[bidPrices[0]].values.reshape(-1, 1)\n",
    "    df_ask.loc[:, askPrices] = df_ask[askPrices] / df[askPrices[0]].values.reshape(-1, 1)\n",
    "    \n",
    "    bid_data = df_bid.values\n",
    "    ask_data = df_ask.values\n",
    "\n",
    "    cum_bid_sizes = np.cumsum(bid_data[:, :5], axis=1) / bid_data[:, :5].sum(axis=1, keepdims=True)\n",
    "    cum_ask_sizes = np.cumsum(ask_data[:, :5], axis=1) / ask_data[:, :5].sum(axis=1, keepdims=True)\n",
    "\n",
    "    bid_price = bid_data[:, 5:]\n",
    "    ask_price = ask_data[:, 5:]\n",
    "\n",
    "    X_bid = cum_bid_sizes - cum_bid_sizes.mean(axis=1, keepdims=True)\n",
    "    Y_bid = bid_price - bid_price.mean(axis=1, keepdims=True)\n",
    "    slope_b = (X_bid * Y_bid).sum(axis=1) / ((X_bid ** 2).sum(axis=1) + 1e-10)\n",
    "\n",
    "    X_ask = cum_ask_sizes - cum_ask_sizes.mean(axis=1, keepdims=True)\n",
    "    Y_ask = ask_price - ask_price.mean(axis=1, keepdims=True)\n",
    "    slope_a = (X_ask * Y_ask).sum(axis=1) / ((X_ask ** 2).sum(axis=1) + 1e-10)\n",
    "\n",
    "    return -slope_b, slope_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features and labels' names to list\n",
    "df_all = {}\n",
    "basicCols = ['date', 'time', 'sAskPrice1','sBidPrice1','sMidQ', 'fAskPrice1','fBidPrice1', 'fMidQ', 'spreadRatio']\n",
    "labelCols = []\n",
    "featureCols = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    labelCols.extend(['Y_M_{}'.format(str(i))])\n",
    "    \n",
    "    featureCols.extend(['fLaggingRtn_{}'.format(str(i))])\n",
    "    featureCols.extend(['spreadRatio_{}'.format(str(i))])\n",
    "    featureCols.extend(['volumeImbalanceRatio_{}'.format(str(i))])\n",
    "    featureCols.extend(['slope_b_{}'.format(str(i))])\n",
    "    featureCols.extend(['slope_a_{}'.format(str(i))])\n",
    "    featureCols.extend(['slope_ab_{}'.format(str(i))])\n",
    "    featureCols.extend(['sLaggingRtn_{}'.format(str(i))])\n",
    "    featureCols.extend(['stockSpreadRatio_{}'.format(str(i))])\n",
    "    featureCols.extend(['stockVolumeImbalanceRatio_{}'.format(str(i))])\n",
    "    featureCols.extend(['stockSlope_b_{}'.format(str(i))])\n",
    "    featureCols.extend(['stockSlope_a_{}'.format(str(i))])\n",
    "    featureCols.extend(['stockSlope_ab_{}'.format(str(i))])\n",
    "    \n",
    "    for j in range(1, 6):\n",
    "        featureCols.extend(['fAskSize{}_{}'.format(str(j), str(i))])\n",
    "        featureCols.extend(['fBidSize{}_{}'.format(str(j), str(i))])\n",
    "        featureCols.extend(['sAskSize{}_{}'.format(str(j), str(i))])\n",
    "        featureCols.extend(['sBidSize{}_{}'.format(str(j), str(i))])\n",
    "\n",
    "# Generate features and labels\n",
    "for future_ticker, futureData in future_data.items():\n",
    "    stockData = stock_data[future2stock[future_ticker]]\n",
    "    unique_dates = np.unique(stockData['date'])\n",
    "    dfs = []\n",
    "    for date in unique_dates:\n",
    "        stockData_date = stockData[stockData['date'] == date]\n",
    "        futureData_date = futureData[futureData['date'] == date]\n",
    "\n",
    "        # Continue to next iteration if stockData_date or futureData_date is empty\n",
    "        if stockData_date.empty or futureData_date.empty:\n",
    "            continue\n",
    "\n",
    "        df = pd.DataFrame(index=stockData_date.index, columns=basicCols+labelCols+featureCols)\n",
    "        df['date'] = stockData_date['date']\n",
    "        df['time'] = stockData_date['time']   \n",
    "             \n",
    "        # Normalize the size\n",
    "        fAskSizeMax = futureData_date[['askSize1', 'askSize2', 'askSize3', 'askSize4', 'askSize5']].max(axis=1)\n",
    "        fBidSizeMax = futureData_date[['bidSize1', 'bidSize2', 'bidSize3', 'bidSize4', 'bidSize5']].max(axis=1)\n",
    "        sAskSizeMax = stockData_date[['SV1', 'SV2', 'SV3', 'SV4', 'SV5']].max(axis=1)\n",
    "        sBidSizeMax = stockData_date[['BV1', 'BV2', 'BV3', 'BV4', 'BV5']].max(axis=1)\n",
    "        \n",
    "        for i in range(1, 6):\n",
    "            df['fAskPrice{}'.format(str(i))] = futureData_date['askPrice{}'.format(str(i))]\n",
    "            df['fBidPrice{}'.format(str(i))] = futureData_date['bidPrice{}'.format(str(i))]\n",
    "            df['fAskSize{}'.format(str(i))] = futureData_date['askSize{}'.format(str(i))] / fAskSizeMax\n",
    "            df['fBidSize{}'.format(str(i))] = futureData_date['bidSize{}'.format(str(i))] / fBidSizeMax\n",
    "            \n",
    "            df['sAskPrice{}'.format(str(i))] = stockData_date['SP{}'.format(str(i))]\n",
    "            df['sBidPrice{}'.format(str(i))] = stockData_date['BP{}'.format(str(i))]\n",
    "            df['sAskSize{}'.format(str(i))] = stockData_date['SV{}'.format(str(i))] / sAskSizeMax\n",
    "            df['sBidSize{}'.format(str(i))] = stockData_date['BV{}'.format(str(i))] / sBidSizeMax\n",
    "        \n",
    "        df['fMidQ'] = (df['fAskPrice1'] + df['fBidPrice1']) / 2\n",
    "        df['slope_b'], df['slope_a'] = cal_slope(futureData_date)\n",
    "        df['slope_ab'] = df['slope_a'] - df['slope_b']\n",
    "        \n",
    "        # Order Imbalance Ratio (OIR)\n",
    "        ask = np.array([df['fAskPrice{}'.format(str(i))] * df['fAskSize{}'.format(str(i))] * (1 - (i - 1) / 5) for i in range(1, 6)]).sum(axis=0)\n",
    "        bid = np.array([df['fBidPrice{}'.format(str(i))] * df['fBidSize{}'.format(str(i))] * (1 - (i - 1) / 5) for i in range(1, 6)]).sum(axis=0)\n",
    "        df['spreadRatio'] = (ask - bid) / (ask + bid)\n",
    "\n",
    "        # Order Flow Imbalance (Only 1 level)\n",
    "        delta_size_bid = np.where(df['fBidPrice1'] < df['fBidPrice1'].shift(1), 0, np.where(df['fBidPrice1'] == df['fBidPrice1'].shift(1), df['fBidSize1'] - df['fBidSize1'].shift(1), df['fBidSize1']))\n",
    "        delta_size_ask = np.where(df['fAskPrice1'] > df['fAskPrice1'].shift(1), 0, np.where(df['fAskPrice1'] == df['fAskPrice1'].shift(1), df['fAskSize1'] - df['fAskSize1'].shift(1), df['fAskSize1']))\n",
    "        df['fOrderImbalance'] = (delta_size_bid - delta_size_ask) / (delta_size_bid + delta_size_ask)\n",
    "        # df['fOrderImbalance'] = (df['fOrderImbalance'] - df['fOrderImbalance'].rolling(10).mean()) / df['fOrderImbalance'].rolling(10).std()\n",
    "        \n",
    "        for i in range(1, 11):\n",
    "            df['fLaggingRtn_{}'.format(str(i))] = np.log(df['fMidQ']) - np.log(df['fMidQ'].shift(i))\n",
    "            df['spreadRatio_{}'.format(str(i))] = df['spreadRatio'].shift(i)\n",
    "            df['volumeImbalanceRatio_{}'.format(str(i))] = df['fOrderImbalance'].shift(i)\n",
    "            df['slope_b_{}'.format(str(i))] = df['slope_b'].shift(i)\n",
    "            df['slope_a_{}'.format(str(i))] = df['slope_a'].shift(i)\n",
    "            df['slope_ab_{}'.format(str(i))] = df['slope_ab'].shift(i)\n",
    "            \n",
    "            for j in range(1, 6):\n",
    "                df['fAskSize{}_{}'.format(str(j), str(i))] = df['fAskSize{}'.format(str(j))].shift(i)\n",
    "                df['fBidSize{}_{}'.format(str(j), str(i))] = df['fBidSize{}'.format(str(j))].shift(i)\n",
    "                df['sAskSize{}_{}'.format(str(j), str(i))] = df['sAskSize{}'.format(str(j))].shift(i)\n",
    "                df['sBidSize{}_{}'.format(str(j), str(i))] = df['sBidSize{}'.format(str(j))].shift(i)\n",
    "\n",
    "        # Add stock data\n",
    "        df['sMidQ'] = (stockData_date['SP1'] + stockData_date['BP1'])/2\n",
    "        df['sAskPrice1'] = stockData_date['SP1']\n",
    "        df['sBidPrice1'] = stockData_date['BP1']\n",
    "        df['sMidQ'] = (stockData_date['SP1'] + stockData_date['BP1'])/2\n",
    "        df['stockSlope_b'], df['stockSlope_a'] = cal_slope(stockData_date)\n",
    "        df['stockSlope_ab'] = df['stockSlope_a'] - df['stockSlope_b']\n",
    "        \n",
    "        ask = np.array([df['sAskPrice{}'.format(str(i))] * df['sAskSize{}'.format(str(i))] * (1 - (i - 1) / 5) for i in range(1, 6)]).sum(axis=0)\n",
    "        bid = np.array([df['sBidPrice{}'.format(str(i))] * df['sBidSize{}'.format(str(i))] * (1 - (i - 1) / 5) for i in range(1, 6)]).sum(axis=0)\n",
    "        df['stockSpreadRatio'] = (ask - bid) / (ask + bid)\n",
    "\n",
    "        delta_size_bid = np.where(df['sBidPrice1'] < df['sBidPrice1'].shift(1), 0, np.where(df['sBidPrice1'] == df['sBidPrice1'].shift(1), df['sBidSize1'] - df['sBidSize1'].shift(1), df['sBidSize1']))\n",
    "        delta_size_ask = np.where(df['sAskPrice1'] > df['sAskPrice1'].shift(1), 0, np.where(df['sAskPrice1'] == df['sAskPrice1'].shift(1), df['sAskSize1'] - df['sAskSize1'].shift(1), df['sAskSize1']))\n",
    "        df['stockOrderImbalance'] = (delta_size_bid - delta_size_ask) / (delta_size_bid + delta_size_ask)\n",
    "        # df['stockOrderImbalance'] = (df['stockOrderImbalance'] - df['stockOrderImbalance'].rolling(10).mean()) / df['stockOrderImbalance'].rolling(10).std()\n",
    "        for i in range(1, 11):\n",
    "            df['Y_M_{}'.format(str(i))] = np.log(df['sMidQ'].shift(-i)) - np.log(df['sMidQ'])\n",
    "            \n",
    "            df['sLaggingRtn_{}'.format(str(i))] = np.log(df['sMidQ']) - np.log(df['sMidQ'].shift(i))\n",
    "            df['stockSpreadRatio_{}'.format(str(i))] = df['stockSpreadRatio'].shift(i)\n",
    "            df['stockVolumeImbalanceRatio_{}'.format(str(i))] = df['stockOrderImbalance'].shift(i)\n",
    "            df['stockSlope_b_{}'.format(str(i))] = df['stockSlope_b'].shift(i)\n",
    "            df['stockSlope_a_{}'.format(str(i))] = df['stockSlope_a'].shift(i)\n",
    "            df['stockSlope_ab_{}'.format(str(i))] = df['stockSlope_ab'].shift(i)\n",
    "            \n",
    "            for j in range(1, 6):\n",
    "                df['sAskSize{}_{}'.format(str(j), str(i))] = df['sAskSize{}'.format(str(j))].shift(i)\n",
    "                df['sBidSize{}_{}'.format(str(j), str(i))] = df['sBidSize{}'.format(str(j))].shift(i)\n",
    "        dfs.append(df)\n",
    "    # Convert inf to nan to 0\n",
    "    df_all[future_ticker] = pd.concat(dfs, ignore_index=True).replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "\n",
    "def objective(trial, x_train, y_train, measure, lookforward_win):\n",
    "    param = {\n",
    "        'metric': 'rmse', \n",
    "        'random_state': 48,\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [3, 5, 7]), \n",
    "        'num_leaves': trial.suggest_categorical('num_leaves', [7, 31, 63, 127]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.8]),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.8]),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**param)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    score = 0\n",
    "    for train_index, val_index in tscv.split(x_train):\n",
    "        x_train_cv, x_val_cv = x_train.iloc[train_index], x_train.iloc[val_index]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        model.fit(x_train_cv, y_train_cv, eval_set=[(x_val_cv, y_val_cv)], early_stopping_rounds=50, verbose=False, callbacks=[LightGBMPruningCallback(trial, 'rmse')])\n",
    "        y_pred = model.predict(x_val_cv)\n",
    "        if measure == 'rmse':\n",
    "            error = mean_squared_error(y_val_cv, y_pred)\n",
    "            score += error\n",
    "        elif measure == 'cum_ret':\n",
    "            error = -backtest(y_val_cv, y_pred, lookforward_win)\n",
    "            score += error\n",
    "    return score / 5\n",
    "\n",
    "\n",
    "def backtest(y_val_cv, pred_series, lookforward_win):\n",
    "    val_df = y_val_cv.copy()\n",
    "    val_df = pd.DataFrame(val_df)\n",
    "    val_df['pred'] = pred_series\n",
    "\n",
    "    # long if pred > 0, short if pred < 0, record the return\n",
    "    val_df['direction'] = np.where(val_df['pred'] > 0, 1, np.where(val_df['pred'] < 0, -1, 0))\n",
    "    val_df['return'] = val_df['Y_M_{}'.format(str(lookforward_win))] * val_df['direction'] / lookforward_win\n",
    "    val_df['return'] = val_df['return'].shift(lookforward_win)\n",
    "    val_df['return'] = val_df['return'].fillna(0)\n",
    "\n",
    "    # calculate the cumulative return\n",
    "    val_df['cum_return'] = val_df['return'].cumsum() + 1\n",
    "    cum_return = val_df['cum_return'].iloc[-1]\n",
    "    print(cum_return)\n",
    "\n",
    "    # std of return\n",
    "    val_df['std'] = val_df['return'].std()\n",
    "\n",
    "    return cum_return\n",
    "\n",
    "\n",
    "def modelConstructionAndForecasting(numOfPastDays:int, numOfForwardDays:int, data:pd.DataFrame, numOfProcesses:int, featureColumns:list, tickers:str, measure:str):\n",
    "    date=data.date\n",
    "    date_index=np.unique(date)\n",
    "    date_num=date_index.size\n",
    "    p=numOfPastDays\n",
    "    \n",
    "    #Output data\n",
    "    columns1 = ['date', 'label', 'isR2', 'oosR2']\n",
    "    outputData = pd.DataFrame(columns=columns1)\n",
    "    \n",
    "    for i in range(date_num-p):\n",
    "        if i >= numOfForwardDays:\n",
    "            break\n",
    "        #Prepare training and testing data for the current testing day\n",
    "        trainingDates=[date_index[i]]\n",
    "        for j in range(i+1,i+p):\n",
    "            trainingDates.append(date_index[j])        \n",
    "\n",
    "        dataPd=data[data.date.isin(trainingDates)]\n",
    "        data1d=data[data.date==date_index[i+p]]\n",
    "\n",
    "        #Building models with LightGBM models for each label\n",
    "        lgbmModels = {}\n",
    "        LGBMModels = {}\n",
    "        for j in range(1, 11):\n",
    "            lgbmModels['Y_M_{}'.format(str(j))] = lgb.LGBMRegressor()\n",
    "        \n",
    "        #Use a dictionry to hold training label data\n",
    "        y_training = {}\n",
    "        for j in range(1, 11):\n",
    "            y_training['Y_M_{}'.format(str(j))] = dataPd['Y_M_{}'.format(str(j))]\n",
    "        \n",
    "        #Hold feature data for training\n",
    "        x_training = pd.DataFrame()\n",
    "        for j in range(len(featureColumns)):\n",
    "            x_training[featureColumns[j]] = dataPd[featureColumns[j]]\n",
    "\n",
    "        #Use a dictionry to hold testing label data\n",
    "        y_testing = {}\n",
    "        for j in range(1, 11):\n",
    "            y_testing['Y_M_{}'.format(str(j))] = data1d['Y_M_{}'.format(str(j))]\n",
    "\n",
    "        #Hold feature data for testing\n",
    "        x_testing = pd.DataFrame()\n",
    "        for j in range(len(featureColumns)):\n",
    "            x_testing[featureColumns[j]] = data1d[featureColumns[j]]\n",
    "\n",
    "        #Use a dictionry to hold predictions\n",
    "        y_prediction = {}\n",
    "\n",
    "        #timing the multi-Process prcessing\n",
    "        t = time.time()\n",
    "        #Construction of models\n",
    "        ##Establish a number of Processs for the calculation tasks\n",
    "        pool = Pool(processes=numOfProcesses)\n",
    "\n",
    "        for j in range(1, 11):\n",
    "            study = optuna.create_study(direction='minimize')\n",
    "            study.optimize(lambda trial: objective(trial, x_training, y_training['Y_M_{}'.format(str(j))], measure, lookforward_win=j), n_trials=10, n_jobs=-1)\n",
    "            best_params = study.best_params\n",
    "            lgbmModels['Y_M_{}'.format(str(j))].set_params(**best_params)\n",
    "            LGBMModels['Y_M_{}'.format(str(j))] = pool.apply_async(lgbmModels['Y_M_{}'.format(str(j))].fit, args=(x_training, y_training['Y_M_{}'.format(str(j))]))\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        print(\">>>Done with \" + str(numOfProcesses) + \" processes, and time taken is \" + str(time.time() - t)) \n",
    "        \n",
    "        # Save the models after all models are fitted\n",
    "        # check if dir exists\n",
    "        if not os.path.exists('./model_params'):\n",
    "            os.makedirs('./model_params')\n",
    "        for j in range(1, 11):\n",
    "            LGBMModels['Y_M_{}'.format(str(j))].get().booster_.save_model('./model_params/model_{}_Y_M_{}.txt'.format(tickers, str(j)))\n",
    "        \n",
    "        #Use the models to predict\n",
    "        for j in range(1, 11):\n",
    "            y_prediction['Y_M_{}'.format(str(j))] = LGBMModels['Y_M_{}'.format(str(j))].get().predict(x_testing)\n",
    "        \n",
    "        #Now, we store modeling results\n",
    "        for j in range(1, 11):\n",
    "            oneLineModelResult = []\n",
    "            oneLineModelResult.extend([str(date_index[i+p])])\n",
    "            oneLineModelResult.extend(['Y_M_{}'.format(str(j))])\n",
    "            oneLineModelResult.extend([LGBMModels['Y_M_{}'.format(str(j))].get().score(x_training, y_training['Y_M_{}'.format(str(j))], me\n",
    "            oneLineModelResult.extend([LGBMModels['Y_M_{}'.format(str(j))].get().score(x_testing, y_testing['Y_M_{}'.format(str(j))])])            \n",
    "            outputData = pd.concat([outputData, pd.DataFrame(data = [oneLineModelResult], columns = columns1)])\n",
    "\n",
    "    return outputData\n",
    "\n",
    "for future_ticker, df in df_all.items():\n",
    "    numOfPastDays = np.unique(df['date']).size - 1\n",
    "    numOfForwardDays = 1\n",
    "    numOfProcesses = 8\n",
    "    measure = 'cum_ret'\n",
    "\n",
    "    start_time = time.time()\n",
    "    outputData = modelConstructionAndForecasting(numOfPastDays, numOfForwardDays, df, numOfProcesses, featureCols, future_ticker, measure)\n",
    "    end_time = time.time()\n",
    "    print('Time taken: ', end_time - start_time, 'seconds')\n",
    "    # Check if dir exists\n",
    "    if not os.path.exists('./modelStats'):\n",
    "        os.makedirs('./modelStats')\n",
    "    outputData.to_csv('./modelStats/modelStats_{}.csv'.format(future_ticker), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the model parameters\n",
    "model_params = {}\n",
    "for future_ticker in future2stock.keys():\n",
    "    model_params[future_ticker] = {}\n",
    "    for i in range(1, 11):\n",
    "        model_params[future_ticker]['Y_M_{}'.format(str(i))] = lgb.Booster(model_file='./model_params/model_{}_Y_M_{}.txt'.format(future_ticker, str(i)))\n",
    "# use the last date as testing data\n",
    "result = []\n",
    "for future_ticker, df in df_all.items():\n",
    "    df_test_date = df[df['date'] == df['date'].iloc[-1]]\n",
    "    df_test_date = df_test_date.reset_index(drop=True)\n",
    "    df_test = df_test_date[featureCols]\n",
    "    # predict\n",
    "    y_pred_backtest = {}\n",
    "    for i in range(1, 11):\n",
    "        y_pred_backtest['Y_M_{}'.format(str(i))] = backtest(df_test_date['Y_M_{}'.format(str(i))], model_params[future_ticker]['Y_M_{}'.format(str(i))].predict(df_test), i)\n",
    "    # save the results\n",
    "    tmp_df = pd.DataFrame(y_pred_backtest, index=[0])\n",
    "    tmp_df = tmp_df.assign(date=df_test_date['date'].iloc[0])\n",
    "    tmp_df = tmp_df.assign(ticker=future_ticker)\n",
    "    result.append(tmp_df)\n",
    "\n",
    "if not os.path.exists('./backtest'):\n",
    "    os.makedirs('./backtest')\n",
    "pd.concat(result).to_csv('./backtest/backtest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the Y_M_1 models\n",
    "import shutil\n",
    "model_files = os.listdir('./model_params')\n",
    "model_files = [file for file in model_files if file.endswith('Y_M_1.txt')]\n",
    "# make a copy of the original model files and make dir\n",
    "if not os.path.exists('./model_params_backup'):\n",
    "    os.makedirs('./modelParamsProd')\n",
    "for file in model_files:\n",
    "    shutil.copy('./model_params/' + file, './modelParamsProd/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
